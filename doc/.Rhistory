library("rvest")
library("tibble")
library("qdap")
library("sentimentr")
library("gplots")
library("dplyr")
library("tm")
library("syuzhet")
library("factoextra")
library("beeswarm")
library("scales")
library("RColorBrewer")
library("RANN")
library("tm")
library("topicmodels")
library("openssl")
library("purrr")
library("twitteR")
library("httr")
library("devtools")
library("base64enc")
library("tidyr")
library("tidytext")
library("stringr")
source("../lib/plotstacked.R")
source("../lib/speechFuncs.R")
main.page <- read_html(x = "http://www.presidency.ucsb.edu/inaugurals.php")
# Get link URLs
# f.speechlinks is a function for extracting links from the list of speeches.
inaug=f.speechlinks(main.page)
#head(inaug)
as.Date(inaug[,1], format="%B %e, %Y")
inaug=inaug[-nrow(inaug),] # remove the last line, irrelevant due to error.
inaug.list=read.csv("../data/inauglist.csv", stringsAsFactors = FALSE)
###nomination speeches
main.page=read_html("http://www.presidency.ucsb.edu/nomination.php")
# Get link URLs
nomin <- f.speechlinks(main.page)
nomin.list=read.csv("../data/nominlist.csv", stringsAsFactors = FALSE)
#### Farewell speeches
main.page=read_html("http://www.presidency.ucsb.edu/farewell_addresses.php")
# Get link URLs
farewell <- f.speechlinks(main.page)
farewell.list=read.csv("../data/farewelllist.csv", stringsAsFactors = FALSE)
speech.list=rbind(inaug.list, nomin.list, farewell.list)
speech.list$type=c(rep("inaug", nrow(inaug.list)),
rep("nomin", nrow(nomin.list)),
rep("farewell", nrow(farewell.list)))
speech.url=rbind(inaug, nomin, farewell)
speech.list=cbind(speech.list, speech.url)
speech.list$fulltext=NA
for(i in seq(nrow(speech.list))) {
text <- read_html(speech.list$urls[i]) %>% # load the page
html_nodes(".displaytext") %>% # isloate the text
html_text() # get the text
speech.list$fulltext[i]=text
# Create the file name
filename <- paste0("../data/",
speech.list$type[i],
speech.list$File[i], "-",
speech.list$Term[i], ".txt")
sink(file = filename) %>% # open file to write
cat(text)  # write the file
sink() # close the file
}
speech1=paste(readLines("../data/SpeechDonaldTrump-NA.txt",
n=-1, skipNul=TRUE),
collapse=" ")
speech2=paste(readLines("../data/SpeechDonaldTrump-NA2.txt",
n=-1, skipNul=TRUE),
collapse=" ")
speech3=paste(readLines("../data/PressDonaldTrump-NA.txt",
n=-1, skipNul=TRUE),
collapse=" ")
speech4=paste(readLines("../data/Trump3.txt",
n=-1, skipNul=TRUE),
collapse=" ")
Trump.speeches=data.frame(
President=rep("Donald J. Trump", 4),
File=rep("DonaldJTrump", 4),
Term=rep(0, 4),
Party=rep("Republican", 4),
Date=c("August 31, 2016", "September 7, 2016", "January 11, 2017","July 21, 2016"),
Words=c(word_count(speech1), word_count(speech2), word_count(speech3), word_count(speech4)),
Win=rep("yes", 4),
type=rep("nomin", 4),
links=rep(NA, 4),
urls=rep(NA, 4),
fulltext=c(speech1, speech2, speech3, speech4)
)
names(speech.list)[1]='President'
speech.list=rbind(speech.list, Trump.speeches)
sentence.list=NULL
for(i in 1:nrow(speech.list)){
sentences=sent_detect(speech.list$fulltext[i],
endmarks = c("?", ".", "!", "|",";"))
if(length(sentences)>0){
emotions=get_nrc_sentiment(sentences)
word.count=word_count(sentences)
# colnames(emotions)=paste0("emo.", colnames(emotions))
# in case the word counts are zeros?
emotions=diag(1/(word.count+0.01))%*%as.matrix(emotions)
sentence.list=rbind(sentence.list,
cbind(speech.list[i,-ncol(speech.list)],
sentences=as.character(sentences),
word.count,
emotions,
sent.id=1:length(sentences)
)
)
}
}
sentence.list=
sentence.list%>%
filter(!is.na(word.count))
load(url("http://varianceexplained.org/files/trump_tweets_df.rda"))
head(trump_tweets_df)
tweets <- trump_tweets_df %>%
select(id, statusSource, text, created) %>%
extract(statusSource, "source", "Twitter for (.*?)<") %>%
filter(source %in% c("Android"))
reg <- "([^A-Za-z\\d#@']|'(?![A-Za-z\\d#@]))"
tweet_words <- tweets %>%
filter(!str_detect(text, '^"')) %>%
mutate(text = str_replace_all(text, "https://t.co/[A-Za-z\\d]+|&", "")) %>%
unnest_tokens(word, text, token = "regex", pattern = reg) %>%
filter(!word %in% stop_words$word,
str_detect(word, "[a-z]"))
wordFreq <- sort(table(tolower(tweet_words$word)),decreasing = TRUE)
wordFreq[1:30]
nrc <- sentiments %>%
filter(lexicon == "nrc") %>%
dplyr::select(word, sentiment)
count<-rep(1,nrow(nrc))
nrc<-data.frame(nrc,count)
percent<-tapply(nrc$count,nrc$sentiment,sum)
x <- c('anger','anticipation','disgust','fear','joy','negative','postive','sadness','surprise','trust')
y <- percent
df <- data.frame(x= x, y = y)
ggplot(data = df, mapping = aes(x = x, y = y,fill=x)) + geom_bar(stat= 'identity')
library(tm)
library(wordcloud)
library(RColorBrewer)
wordFreq2<-wordFreq/nrow(tweet_words)
wordcloud(tweet_words$word, scale=c(5,0.5),
max.words=100,
min.freq=3,
random.order=FALSE,
rot.per=0.3,
use.r.layout=T,
random.color=FALSE,
colors=brewer.pal(9,"Blues"))
date_express <- "^[0-9]{4}-[0-9]{2}-[0-9]{2}"
date<-grep(trump_tweets_df$created, pattern = date_express, invert = TRUE, value = TRUE)
date
date<-grep(trump_tweets_df$created, pattern = date_express, invert = TRUE, value = TRUE)
date
head(grep(trump_tweets_df$created, pattern = date_express))
head(grep(trump_tweets_df$created, pattern = date_express, value = TRUE))
date<-grep(trump_tweets_df$created, pattern = date_express, value = TRUE)
date
date1<-gsub("[0-9]{2}:[0-9]{2}:[0-9]{2}","",date)
head(date1)
date1<-unique(date1)
head(date1)
plot(date1)
date1<-gsub("[0-9]{2}:[0-9]{2}:[0-9]{2}","",date)
dateFreq <- sort(date1,decreasing = TRUE)
dateFreq[1:30]
date1<-gsub(" [0-9]{2}:[0-9]{2}:[0-9]{2}","",date)
dateFreq <-sort(table(tolower(date1)),decreasing = TRUE)
dateFreq[1:30]
date1[dateFreq[1:30]]
df <- data.frame(x= x, y = y)
ggplot(df, mapping=aes(x=x, y=y)) + geom_line(linetype="dotted")
y[1]
x<-date1[dateFreq[1:30]]
y<-dateFreq[1:30]
df <- data.frame(x= x, y = y)
ggplot(df, mapping=aes(x=x, y=y)) + geom_line(linetype="dotted")
y
x
plot(y)
y<-dateFreq[1:30]
plot(y)
plot(y,type="l")
y<-dateFreq
plot(y,type="l")
plot(y,type="l",main="Created date")
plot(y,type="l",main="Created date",ylab="Freq",xla="Date")
